# Llama Stack Operator Instance configuration
MODEL_NAME_0: "nvidia/llama-3.3-nemotron-super-49b-v1.5"
MODEL_URL_0: "https://integrate.api.nvidia.com/v1"
MODEL_API_TOKEN_0: ""

MODEL_NAME_1: "nvidia/llama-3.2-nv-embedqa-1b-v2"
MODEL_URL_1: "http://embedded-qa-predictor.nimtest.svc.cluster.local:8000/v1"

MODEL_NAME_2: "nvidia/llama-3.2-nv-rerankqa-1b-v2"
MODEL_URL_2: "http://rerank-predictor.nimtest.svc.cluster.local:8000/v1"


# Distribution configuration
distribution:
  image: "quay.io/rhoai-genaiops/llama-stack-vllm-milvus-fms:rhoai-3.0-fix2"


# ConfigMap for Llama Stack configuration
configMap:
  enabled: true

# Telemetry configuration
telemetry:
  enabled: true

rag:
  enabled: false
  milvus:
    service: "milvus-test"

mcp:
  enabled: false

otelCollector:
  enabled: true

eval:
  enabled: false

guardrails:
  enabled: false
  regex:
    enabled: false
    filter: ["(?i).*fight club.*"]
  hap:
    enabled: false
  prompt_injection:
    enabled: false
  language_detection:
    enabled: false
